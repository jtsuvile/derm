{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# LOADING LIBRARY"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import plotly.io as pio\n","pio.renderers.default = 'iframe_connected'\n"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-11-01 12:19:13.902458: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination\n","2021-11-01 12:19:13.902508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpuderm\n","2021-11-01 12:19:13.902518: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpuderm\n","2021-11-01 12:19:13.902600: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.63.1\n","2021-11-01 12:19:13.902626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.57.2\n","2021-11-01 12:19:13.902635: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 470.57.2 does not match DSO version 470.63.1 -- cannot find working devices in this configuration\n","2021-11-01 12:19:13.903374: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","#import openslide\n","import os\n","import cv2\n","import PIL\n","from IPython.display import Image, display\n","from keras.applications.vgg16 import VGG16,preprocess_input\n","import plotly.graph_objs as go\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential, Model,load_model\n","from keras.applications.vgg16 import VGG16,preprocess_input\n","#from keras.applications.resnet50 import ResNet50\n","from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\n","from keras.layers import GlobalMaxPooling2D\n","from keras.models import Model\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","#from keras.optimizers import SGD, RMSprop\n","from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n","#from keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import gc\n","import skimage.io\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf\n","from tensorflow.python.keras import backend as K\n","sess = K.get_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["train=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sub=pd.read_csv('/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sub.head()"]},{"cell_type":"markdown","metadata":{},"source":["### LOAD ALL THE IMAGES FROM JPEG TRAIN DATASET AND SAVE ALL PATH TO DF DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["labels=[]\n","data=[]\n","data_dir='/kaggle/input/siim-isic-melanoma-classification/jpeg/train'\n","for i in range(train.shape[0]):\n","    data.append(data_dir + train['image_name'].iloc[i]+'.jpg')\n","    labels.append(train['target'].iloc[i])\n","df=pd.DataFrame(data)\n","df.columns=['images']\n","df['target']=labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.preprocessing import image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["'''\n","train_image = []\n","for i in range(train.shape[0]):\n","    img = image.load_img('/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'+train['image_name'].iloc[i]+'.jpg', target_size=(28,28,1), grayscale=True)\n","    img = image.img_to_array(img)\n","    img = img/255\n","    train_image.append(img)\n","X = np.array(train_image)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["'''\n","import glob\n","import cv2\n","import numpy as np\n","pic_num=1\n","IMG_DIR='/kaggle/input/siim-isic-melanoma-classification/jpeg/train/'\n","def read_images(directory):\n","    for img in glob.glob(directory+\"/*.jpg\"):\n","        image = cv2.imread(img)\n","        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        train_image = cv2.resize(image/255.0  , (32 , 32))\n","        #cv2.imwrite(\"small/\"+str(pic_num)+'.jpg',resized_img)\n","\n","        yield train_image\n","\n","train_image =  np.array(list(read_images(IMG_DIR)))\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train['target'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(df['images'],df['target'], test_size=0.2, random_state=1234)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train=pd.DataFrame(X_train)\n","train.columns=['images']\n","train['target']=y_train\n","\n","validation=pd.DataFrame(X_val)\n","validation.columns=['images']\n","validation['target']=y_val\n","\n","train['target']=train['target'].astype(str)\n","validation['target']=validation['target'].astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["validation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_datagen = ImageDataGenerator()\n","                                   #,rotation_range=20,\n","    #width_shift_range=0.2,\n","    #height_shift_range=0.2,horizontal_flip=True)\n","val_datagen=train_datagen = ImageDataGenerator()\n","train_generator = train_datagen.flow_from_dataframe(\n","    train,\n","    x_col='images',\n","    y_col='target',\n","    target_size=(224, 224)\n","    #batch_size=32,\n","    #class_mode='categorical'\n",")\n","\n","validation_generator = val_datagen.flow_from_dataframe(\n","    validation,\n","    x_col='images',\n","    y_col='target',\n","    target_size=(224, 244)\n","    #batch_size=32,\n","    #class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.applications import VGG16\n","\n","# include top should be False to remove the softmax layer\n","pretrained_model = VGG16(include_top=False, weights='imagenet')\n","pretrained_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def vgg16_model( num_classes=None):\n","\n","    model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x=Flatten()(model.output)\n","    x=Dropout(0.5)(x)\n","    output=Dense(num_classes,activation='softmax')(x)\n","    model=Model(model.input,output)\n","    return model\n","\n","vgg_conv=vgg16_model(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vgg_conv.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def kappa_score(y_true, y_pred):\n","    \n","    y_true=tf.math.argmax(y_true)\n","    y_pred=tf.math.argmax(y_pred)\n","    return tf.compat.v1.py_func(cohen_kappa_score ,(y_true, y_pred),tf.double)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["opt = SGD(0.001,momentum=0.9,decay=1e-4)\n","vgg_conv.compile(loss='categorical_crossentropy',optimizer=opt,metrics=[kappa_score])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["nb_epochs = 5\n","batch_size=32\n","nb_train_steps = train.shape[0]//batch_size\n","nb_val_steps=validation.shape[0]//batch_size\n","print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps,nb_val_steps))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vgg_conv.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_steps,\n","    epochs=nb_epochs,\n","    validation_data=validation_generator,\n","    validation_steps=nb_val_steps)"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# submission code from https://www.kaggle.com/frlemarchand/high-res-samples-into-multi-input-cnn-keras\n","def predict_submission(df, path):\n","    \n","    df[\"image_path\"] = [path+image_id+\".tiff\" for image_id in df[\"image_name\"]]\n","    df[\"target\"] = 0\n","    predictions = []\n","    for idx, row in df.iterrows():\n","        print(row.image_path)\n","        img=skimage.io.imread(str(row.image_path))\n","        img = cv2.resize(img, (224,224))\n","        img = cv2.resize(img, (224,224))\n","        img = img.astype(np.float32)/255.\n","        img=np.reshape(img,(1,224,224,3))\n","        prediction=vgg_conv.predict(img)\n","        predictions.append(np.argmax(prediction))\n","            \n","    df[\"target\"] = predictions\n","    df = df.drop('image_path', 1)\n","    return df[[\"image_name\",\"target\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_path = \"'/kaggle/input/siim-isic-melanoma-classification/jpeg/train\"\n","submission_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/sample_submission.csv\")\n","\n","if os.path.exists(test_path):\n","    test_df = pd.read_csv(\"/kaggle/input/siim-isic-melanoma-classification/test.csv\")\n","    submission_df = predict_submission(test_df, test_path)\n","\n","submission_df.to_csv('submission.csv', index=False)\n","submission_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.utils import to_categorical\n","# extract train and val features\n","vgg_features_train = pretrained_model.predict(train_generator)\n","vgg_features_val = pretrained_model.predict(validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vgg_features_train"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model2 = Sequential()\n","model2.add(Flatten(input_shape=(7,7,512)))\n","model2.add(Dense(100, activation='relu'))\n","model2.add(Dropout(0.5))\n","model2.add(BatchNormalization())\n","model2.add(Dense(10, activation='softmax'))\n","\n","# compile the model\n","model2.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n","\n","model2.summary()\n","\n","# train model using features generated from VGG16 model\n","\n","#model2.fit(vgg_features_train, epochs=50,  validation_data=vgg_features_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"a92a755ba0f54404f1442331f21c926c3f93ff3adb3a8c2f95922dfa1bebe07e"},"kernelspec":{"display_name":"Python 3.8.11 64-bit ('py38_pytorch': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":4}
